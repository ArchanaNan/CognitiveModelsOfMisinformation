{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45fe04d",
   "metadata": {},
   "source": [
    "# IBL Modeling - Experiment 1\n",
    "\n",
    "The objective of this notebook is to fit the experiment data for 183 participants from Experiment 1 to a computational cognitive model and observe the results. The candidate model for this application is built on the Instance-based learning theory.\n",
    "\n",
    "The first step in order to execute this, is to install the `speedyibl` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0809ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install speedyibl\n",
    "from speedyibl import Agent\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "#import evaluate\n",
    "import time # to calculate time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e13b27-013f-40da-863b-638fed814aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "uri = \"mongodb+srv://archanan:hGKhjjxhr8I891i9@archcluster0.i1cmz5h.mongodb.net/?retryWrites=true&w=majority&appName=ArchCluster0\"\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c76a0d-12af-43de-9b2d-e863b1f05f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expt1_claims_collection']\n"
     ]
    }
   ],
   "source": [
    "database = client[\"expt_claims_database\"]\n",
    "collection = database[\"expt1_claims_collection\"]\n",
    "print(database.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd905cbf-587c-4256-8c84-10aa321f9795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37453271219041634"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def llm_similarity(img_name1, img_name2, db_collection):\n",
    "    sim_dict = db_collection.find_one({ \"img_name\" : img_name1 }, {'length': 0, 'acc_status': 0, 'user_name': 0, 'Category': 0, 'text': 0, 'feedback': 0, 'text_embedding_optimised': 0})['scaled_similarity_dict']\n",
    "    return sim_dict[img_name2]\n",
    "llm_similarity('pretest_tweet_2.jpg', 'pretest_tweet_1.jpg', collection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b62aced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Feedback_Frequency</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>is_fact</th>\n",
       "      <th>is_misinfo</th>\n",
       "      <th>gets_feedback</th>\n",
       "      <th>Assessment</th>\n",
       "      <th>Action</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>response_time</th>\n",
       "      <th>test_stage</th>\n",
       "      <th>text</th>\n",
       "      <th>Category</th>\n",
       "      <th>response_mins_adj</th>\n",
       "      <th>trust_scaled</th>\n",
       "      <th>conservativeness_scaled</th>\n",
       "      <th>acc_status</th>\n",
       "      <th>length_per</th>\n",
       "      <th>correct_assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Experiment1_Partcipant1</td>\n",
       "      <td>75</td>\n",
       "      <td>pretest_tweet_1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>25898</td>\n",
       "      <td>pretest</td>\n",
       "      <td>Majority of lawmakers in 116th Congress are mi...</td>\n",
       "      <td>politics_</td>\n",
       "      <td>0.431633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Experiment1_Partcipant1</td>\n",
       "      <td>75</td>\n",
       "      <td>pretest_tweet_2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>26730</td>\n",
       "      <td>pretest</td>\n",
       "      <td>Launch Directional Robot Intelligent Circuitry...</td>\n",
       "      <td>sports_</td>\n",
       "      <td>0.445500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0.616477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Experiment1_Partcipant1</td>\n",
       "      <td>75</td>\n",
       "      <td>pretest_tweet_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>21060</td>\n",
       "      <td>pretest</td>\n",
       "      <td>Once you’ve had the novel Coronavirus, you are...</td>\n",
       "      <td>covid-19_Spread</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Experiment1_Partcipant1</td>\n",
       "      <td>75</td>\n",
       "      <td>pretest_tweet_4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>20802</td>\n",
       "      <td>pretest</td>\n",
       "      <td>Latest on spread.\\nThere is growing evidence t...</td>\n",
       "      <td>covid-19_Spread</td>\n",
       "      <td>0.346700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0.696023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Experiment1_Partcipant1</td>\n",
       "      <td>75</td>\n",
       "      <td>pretest_tweet_5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>10249</td>\n",
       "      <td>pretest</td>\n",
       "      <td>GM has pledged to stop making gasoline-powered...</td>\n",
       "      <td>business_</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>unverified</td>\n",
       "      <td>1.036932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index           Participant_ID  Feedback_Frequency             stimulus  \\\n",
       "0      2  Experiment1_Partcipant1                  75  pretest_tweet_1.jpg   \n",
       "1      3  Experiment1_Partcipant1                  75  pretest_tweet_2.jpg   \n",
       "2      4  Experiment1_Partcipant1                  75  pretest_tweet_3.jpg   \n",
       "3      5  Experiment1_Partcipant1                  75  pretest_tweet_4.jpg   \n",
       "4      6  Experiment1_Partcipant1                  75  pretest_tweet_5.jpg   \n",
       "\n",
       "   is_fact  is_misinfo  gets_feedback  Assessment  Action  Confidence  ...  \\\n",
       "0        1           0              0           1       1          67  ...   \n",
       "1        1           0              0           0       1          18  ...   \n",
       "2        0           1              0           0       4         100  ...   \n",
       "3        1           0              0           1       0          85  ...   \n",
       "4        1           0              0           1       0         100  ...   \n",
       "\n",
       "   response_time test_stage  \\\n",
       "0          25898    pretest   \n",
       "1          26730    pretest   \n",
       "2          21060    pretest   \n",
       "3          20802    pretest   \n",
       "4          10249    pretest   \n",
       "\n",
       "                                                text         Category  \\\n",
       "0  Majority of lawmakers in 116th Congress are mi...        politics_   \n",
       "1  Launch Directional Robot Intelligent Circuitry...          sports_   \n",
       "2  Once you’ve had the novel Coronavirus, you are...  covid-19_Spread   \n",
       "3  Latest on spread.\\nThere is growing evidence t...  covid-19_Spread   \n",
       "4  GM has pledged to stop making gasoline-powered...        business_   \n",
       "\n",
       "   response_mins_adj trust_scaled conservativeness_scaled  acc_status  \\\n",
       "0           0.431633          1.0                0.428571  unverified   \n",
       "1           0.445500          1.0                0.428571  unverified   \n",
       "2           0.351000          1.0                0.428571  unverified   \n",
       "3           0.346700          1.0                0.428571  unverified   \n",
       "4           0.170817          1.0                0.428571  unverified   \n",
       "\n",
       "   length_per  correct_assessment  \n",
       "0    0.670455                   1  \n",
       "1    0.616477                   0  \n",
       "2    0.698864                   1  \n",
       "3    0.696023                   1  \n",
       "4    1.036932                   1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all users from Experiment 1\n",
    "users_info_df = pd.read_excel(\"CognitiveModelHelper_Exp1.xlsx\", sheet_name=\"Cognitive_Model_Helper_Dataset\")\n",
    "users_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f626616",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_list = users_info_df.Participant_ID.unique()\n",
    "#Remove participant 46\n",
    "participant_list_final = [p for p in participant_list]\n",
    "del participant_list_final[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0aeabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(agent_name):\n",
    "    agent_df = users_info_df.loc[users_info_df['Participant_ID'] == agent_name]\n",
    "    agent = Agent(default_utility=2.0)\n",
    "    agent.similarity([0], lambda x, y: llm_similarity(x , y)) #llm_similarity\n",
    "    agent.similarity([1], lambda x, y: 1 - abs(x - y)) #length_per\n",
    "    agent.similarity([2], lambda x, y: int(x == y)) #category\n",
    "    agent.similarity([3], lambda x, y: int(x == y))\n",
    "    agent.similarity([4], lambda x, y: int(x == y))\n",
    "    runs = 1000 # number of runs (participants)\n",
    "    trials = 15 # number of trials (episodes)\n",
    "    trial_assessments = agent_df.loc[agent_df['test_stage'] == 'posttest']['Assessment'].to_list()\n",
    "    agent_trust = agent_df['trust_scaled'].to_list()[0]\n",
    "    agent_conservativeness = agent_df['conservativeness_scaled'].to_list()[0]\n",
    "    trial_labels = agent_df.loc[agent_df['test_stage'] == 'posttest']['is_fact'].to_list()\n",
    "    average_p = [] # to store average of performance (proportion of maximum reward expectation choice)\n",
    "    average_time = [] # to save time\n",
    "    predictions = []\n",
    "    for r in range(runs):\n",
    "        pmax = []\n",
    "        ttime = [0]\n",
    "        agent.reset() #clear the memory for a new run\n",
    "        agent.similarity([0], lambda x, y: llm_similarity(x , y)) #llm_similarity\n",
    "        agent.similarity([1], lambda x, y: 1 - abs(x - y)) #length_per\n",
    "        agent.similarity([2], lambda x, y: int(x == y)) #category\n",
    "        agent.similarity([3], lambda x, y: int(x == y))\n",
    "        agent.similarity([4], lambda x, y: int(x == y))\n",
    "        #prepopulate with pretest actions\n",
    "        pretest_assessments = agent_df.loc[agent_df['test_stage'] == 'pretest']['Assessment'].to_list()\n",
    "        pretest_stimulus = agent_df.loc[agent_df['test_stage'] == 'pretest']['stimulus'].to_list()\n",
    "        pretest_labels = agent_df.loc[agent_df['test_stage'] == 'pretest']['is_fact'].to_list()\n",
    "        pretest_categories = agent_df.loc[agent_df['test_stage'] == 'pretest']['Category'].to_list()\n",
    "        pretest_claims = agent_df.loc[agent_df['test_stage'] == 'pretest']['text'].to_list()\n",
    "        pretest_rt = agent_df.loc[agent_df['test_stage'] == 'pretest']['response_time'].to_list()\n",
    "        pretest_rt_adj = agent_df.loc[agent_df['test_stage'] == 'pretest']['response_mins_adj'].to_list()\n",
    "        pretest_length_per = agent_df.loc[agent_df['test_stage'] == 'pretest']['length_per'].to_list()\n",
    "        pretest_acc_status = agent_df.loc[agent_df['test_stage'] == 'pretest']['acc_status'].to_list()\n",
    "        sim_time = 0\n",
    "        for i in range(15):\n",
    "            sim_time = sim_time + pretest_rt[i]\n",
    "            agent.populate_at((pretest_stimulus[i], pretest_length_per[i], pretest_categories[i], pretest_acc_status[i], pretest_assessments[i]), 0, sim_time) #change to populate_at\n",
    "            #populate with training choices\n",
    "        training_assessments = agent_df.loc[agent_df['test_stage'] == 'training']['Assessment'].to_list()\n",
    "        training_stimulus = agent_df.loc[agent_df['test_stage'] == 'training']['stimulus'].to_list()\n",
    "        training_labels = agent_df.loc[agent_df['test_stage'] == 'training']['is_fact'].to_list()\n",
    "        training_categories = agent_df.loc[agent_df['test_stage'] == 'training']['Category'].to_list()\n",
    "        training_claims = agent_df.loc[agent_df['test_stage'] == 'training']['text'].to_list()\n",
    "        training_rt = agent_df.loc[agent_df['test_stage'] == 'training']['response_time'].to_list()\n",
    "        training_rt_adj = agent_df.loc[agent_df['test_stage'] == 'training']['response_mins_adj'].to_list()\n",
    "        training_length_per = agent_df.loc[agent_df['test_stage'] == 'training']['length_per'].to_list()\n",
    "        training_acc_status = agent_df.loc[agent_df['test_stage'] == 'training']['acc_status'].to_list()\n",
    "        gets_feedback = agent_df.loc[agent_df['test_stage'] == 'training']['gets_feedback'].to_list()\n",
    "        for i in range(22):\n",
    "            sim_time = sim_time + training_rt[i]\n",
    "            if gets_feedback == 1:\n",
    "                agent.populate_at((training_stimulus[i], training_length_per[i], training_categories[i], training_acc_status[i], training_assessments[i]), 40*int(training_labels[i] == training_assessments[i]), sim_time)\n",
    "            else:\n",
    "                #possibility of incorporating belief-based rewards in a future iteration\n",
    "                agent.populate_at((training_stimulus[i], training_length_per[i], training_categories[i], training_acc_status[i], training_assessments[i]), 0, sim_time)\n",
    "        #evaluate posttest decisions\n",
    "        posttest_assessments = agent_df.loc[agent_df['test_stage'] == 'posttest']['Assessment'].to_list()\n",
    "        posttest_stimulus = agent_df.loc[agent_df['test_stage'] == 'posttest']['stimulus'].to_list()\n",
    "        posttest_labels = agent_df.loc[agent_df['test_stage'] == 'posttest']['is_fact'].to_list()\n",
    "        posttest_categories = agent_df.loc[agent_df['test_stage'] == 'posttest']['Category'].to_list()\n",
    "        posttest_claims = agent_df.loc[agent_df['test_stage'] == 'posttest']['text'].to_list()\n",
    "        posttest_rt = agent_df.loc[agent_df['test_stage'] == 'posstest']['response_time'].to_list()\n",
    "        posttest_rt_adj = agent_df.loc[agent_df['test_stage'] == 'posttest']['response_mins_adj'].to_list()\n",
    "        posttest_length_per = agent_df.loc[agent_df['test_stage'] == 'posttest']['length_per'].to_list()\n",
    "        posttest_acc_status = agent_df.loc[agent_df['test_stage'] == 'posttest']['acc_status'].to_list()\n",
    "        choices = []\n",
    "        for i in range(trials):\n",
    "            options = [(posttest_stimulus[i], posttest_length_per[i], posttest_categories[i], posttest_acc_status[i], 0), (posttest_stimulus[i], posttest_length_per[i], posttest_categories[i], posttest_acc_status[i], 1)]\n",
    "            choice = agent.choose(options)\n",
    "            agent.respond(0)\n",
    "            choices.append(choice[4])\n",
    "        predictions.append(choices)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3011462-8f34-46c7-9957-e0db6c112eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_test = run_model('Experiment1_Partcipant141')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1423c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_avg_accuracy = []\n",
    "participant_max_accuracy = []\n",
    "participant_avg_prediction = []\n",
    "for participant in participant_list_final[:5]:\n",
    "    predictions = run_model(participant)\n",
    "    predictions_mat = np.asarray(predictions)\n",
    "    mean_predictions = np.mean(predictions_mat, axis = 0).tolist()\n",
    "    participant_avg_prediction.append(mean_predictions)\n",
    "    assessments = users_info_df.loc[(users_info_df['test_stage'] == 'posttest')&(users_info_df['Participant_ID'] == participant)]['Assessment'].to_list()\n",
    "    accuracy = []\n",
    "    for i in range(1000):\n",
    "        prediction = predictions[i]\n",
    "        accuracy.append(sum([1 - abs(prediction[i] - assessments[i])for i in range(len(assessments))])/len(assessments))\n",
    "    participant_avg_accuracy.append(np.mean(accuracy))\n",
    "    participant_max_accuracy.append(np.max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ea761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.484,\n",
       " 0.496,\n",
       " 0.488,\n",
       " 0.5,\n",
       " 0.496,\n",
       " 0.535,\n",
       " 0.486,\n",
       " 0.529,\n",
       " 0.499,\n",
       " 0.479,\n",
       " 0.514,\n",
       " 0.515,\n",
       " 0.507,\n",
       " 0.528,\n",
       " 0.486]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_avg_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db6a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.493, 0.508, 0.477, 0.486, 0.492, 0.459, 0.479, 0.515, 0.509,\n",
       "       0.47 , 0.475, 0.504, 0.5  , 0.469, 0.493])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.asarray(pred_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf419e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
